{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make data accessible to team of data scientist\n",
    "#Connect to workspace\n",
    "import azureml.core\n",
    "from auzreml.core import Workspace\n",
    "\n",
    "#Load workspace from saved config file\n",
    "ws=Workspace.from_config()\n",
    "print('Ready to use AzureML {} to work with {}'.format(azureml.core.VERSION,ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work with datastore\n",
    "#In Azure ML, datastores are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace. If you need to work with data that is stored in different locations, \n",
    "#you can add custom datastores to your workspace and set any of them to be the default.\n",
    "\n",
    "#View datastore in current workspace\n",
    "default_ds=ws.get_default_datastore()#datastores could be viewed and mangaed thourgh ml studio\n",
    "\n",
    "#Upload to datastore\n",
    "#you can upload files from your local file system to a datastore so that it\n",
    "#will be accessible to experiments running in the workspace, regardless of where the experiment script is actually being run\n",
    "default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)\n",
    "\n",
    "#Train a model from datastore\n",
    "#The following code gets a reference to the diabetes-data folder where you uploaded the diabetes CSV files, and specifically configures the data reference for download - \n",
    "#other words, it can be used to download the contents of the folder to the compute context where the data reference is being used\n",
    "data_ref = default_ds.path('diabetes-data').as_download(path_on_compute='diabetes_data')\n",
    "print(data_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a folder for the experiment files and write the experiment script\n",
    "import os \n",
    "#Create a folder for experiment files\n",
    "experiment_folder='diabetes_training_from_datastore'\n",
    "os.makedirs(experiment_folder,exist_ok=True)\n",
    "print(experiment_folder, 'folder created')\n",
    "\n",
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "import os \n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Get paramaters\n",
    "parser=argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder reference')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "#Get the experiment run context\n",
    "run=Run.get_context()\n",
    "\n",
    "#Load diabetes data from data reference\n",
    "data_folder=args.data_folder\n",
    "print('Lodingd data from', data_folder)\n",
    "#Load all files and concatenate contents into a single dataframe\n",
    "all_files=os.listdir(data_folder)\n",
    "diabetes=pd.concat((pd.read_csv(os.path.join(data_folder,csv_file)) for csv_file in all_files))\n",
    "\n",
    "#Seperate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "#Split data in to training data and test data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=0)\n",
    "\n",
    "#Train a logistic regression model\n",
    "print('Training logistic regression model with a regularization rate of ', reg)\n",
    "run.log('Regularization Rate',np.float(reg))\n",
    "model=LogisticRegression(C=1/reg,solver='liblinear').fit(X_train,y_train)\n",
    "\n",
    "#Calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "#Calculate auc\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with dataset\n",
    "you can read data directly from datastores, azure ml provides a further abstraction. Dataset is a reference to a sepcific set of data. Datasets can be \n",
    "tabular or file-based."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "#get the default datastore\n",
    "default_ds=ws.get_default_datastore()\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore(may take a while)\n",
    "tab_data_set=Dataset.Tabular.from_delimited_files(path=(default_ds,'diabetes-data/*.csv'))\n",
    "\n",
    "#Display the first 20 rows as a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
