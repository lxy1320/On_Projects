{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting and Mitigating Unfairness in the Model\n",
    "For example, a model that predicts the likelihood of diabetes might work well for some age groups, but not for others - subjecting a subset of patients to unnecessary tests, or depriving them of tests that would confirm a diabetes diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model\n",
    "In addition to splitting the data into training a test sets of features and labels, you'll extract sensitive features that are used to define subpopulations of the data for which you want to compare fairness.In this case, you'll use the Age column to define two categories of patient: those over 50 years old, and those 50 or younger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
    "X, y = data[features].values, data['Diabetic'].values\n",
    "\n",
    "# Get sensitive features\n",
    "S = data[['Age']].astype(int)\n",
    "# Change value to represent age groups\n",
    "S['Age'] = np.where(S.Age > 50, 'Over 50', '50 or younger')\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test, S_train, S_test = train_test_split(X, y, S, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "diabetes_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the selection_rate_group_summary function to return the selection rate (percentage of positive predictions) for the overall population and for each age group in the Age sensitive feature.\n",
    "#Use the group_summary function to calculate prediction performance based on three commomly used classification metrics (accuracy, precision, and recall) \n",
    "#for the overall population and for each age group in the Age sensitive feature. Note that scikit-learn metric scores are used to calculate the performance values.\n",
    "from fairlearn.metrics import selection_rate_group_summary\n",
    "from fairlearn.metrics import group_summary\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Get predictions for the witheld test data\n",
    "y_hat = diabetes_model.predict(X_test)\n",
    "\n",
    "# Get selection rates\n",
    "selection_rates = selection_rate_group_summary(y_test, y_hat, sensitive_features=S_test['Age'])\n",
    "print(\"Selection Rates\\n\",selection_rates)\n",
    "\n",
    "# Get accuracy scores\n",
    "accuracy_scores = group_summary(accuracy_score, y_test, y_hat, sensitive_features=S_test['Age'])\n",
    "print(\"\\nAccuracy\\n\",accuracy_scores)\n",
    "\n",
    "# Get precision scores\n",
    "precision_scores = group_summary(precision_score, y_test, y_hat, sensitive_features=S_test['Age'])\n",
    "print(\"\\nPrecision\\n\",precision_scores)\n",
    "\n",
    "# Get recall scores\n",
    "recall_scores = group_summary(recall_score, y_test, y_hat, sensitive_features=S_test['Age'])\n",
    "print(\"\\nRecall\\n\",recall_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these metrics,  you should be able to discern (recognize) that a larger proportion of the older patients are predicted to be diabetic. Accuracy should be more or less equal for the two groups, but a closer inspection of precision and recall indicates some disparity (inconsistency) in how well the model predicts for each age group.\n",
    "\n",
    "In this scenario, consider recall. The model does a better job of this for patients in the older age group than for younger patients.\n",
    "It's often easier to compare metrics visually. To do this, you'll use the Fairlearn dashboard:\n",
    "\n",
    "Run the cell below.\n",
    "When the widget is displayed, use the Get started link to start configuring your visualization.\n",
    "Select the sensitive features you want to compare (in this case, there's only one: Age).\n",
    "Select the model performance metric you want to compare (in this case, it's a binary classification model so the options are Accuracy, Balanced accuracy, Precision, and Recall). Start with Recall.\n",
    "View the dashboard visualization, which shows:\n",
    "Disparity in performance - how the selected performance metric compares for the subpopulations, including underprediction (false negatives) and overprediction (false positives).\n",
    "Disparity in predictions - A comparison of the number of positive cases per subpopulation.\n",
    "Edit the configuration to compare the predictions based on different performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.widget import FairlearnDashboard\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairlearnDashboard(sensitive_features=S_test, \n",
    "                   sensitive_feature_names=['Age'],\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"diabetes_model\": diabetes_model.predict(X_test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we exclude the Age feature when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-312d464761d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mageless\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mageless\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mageless\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Diabetic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "# Separate features and labels\n",
    "ageless = features.copy()\n",
    "ageless.remove('Age')\n",
    "X2, y2 = data[ageless].values, data['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train2, X_test2, y_train2, y_test2, S_train2, S_test2 = train_test_split(X2, y2, S, test_size=0.20, random_state=0, stratify=y2)\n",
    "\n",
    "# Train a classification model\n",
    "print(\"Training model...\")\n",
    "ageless_model = DecisionTreeClassifier().fit(X_train2, y_train2)\n",
    "print(\"Model trained.\")\n",
    "\n",
    "# View this model in Fairlearn's fairness dashboard, and see the disparities which appear:\n",
    "FairlearnDashboard(sensitive_features=S_test2, \n",
    "                   sensitive_feature_names=['Age'],\n",
    "                   y_true=y_test2,\n",
    "                   y_pred={\"ageless_diabetes_model\": ageless_model.predict(X_test2)})\n",
    "\n",
    "#In this scenario, simply removing the Age feature slightly reduces the disparity in recall, but increases the disparity in precision and accuracy. \n",
    "#This underlines one the key difficulties in applying fairness to machine learning models - you must be clear about what fairness means in a particular context, and optimize for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the Model and Upload the Dashboard Data to Azure ML\n",
    "It might be useful to register the model in your Azure Machine Learning workspace and create an experiment to record the dashboard data so you can track and share your fairness analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the Azure ML workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to work with', ws.name)\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=diabetes_model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "registered_model = Model.register(model_path=model_file,\n",
    "                                  model_name='diabetes_classifier',\n",
    "                                  workspace=ws)\n",
    "model_id= registered_model.id\n",
    "\n",
    "print('Model registered.', model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the FairLearn package to create binary classification group metric sets for one or more models, and use an Azure Machine Learning experiment to upload the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics._group_metric_set import _create_group_metric_set\n",
    "from azureml.contrib.fairness import upload_dashboard_dictionary, download_dashboard_by_upload_id\n",
    "\n",
    "#  Create a dictionary of model(s) you want to assess for fairness \n",
    "sf = { 'Age': S_test.Age}\n",
    "ys_pred = { model_id:diabetes_model.predict(X_test) }\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                    predictions=ys_pred,\n",
    "                                    sensitive_features=sf,\n",
    "                                    prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, \"Diabetes_Fairness\")\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:In this exercise, you'll use the GridSearch feature, which trains multiple models in an attempt to minimize the disparity of predictive performance for the sensitive features in the dataset (in this case, the age groups). You'll optimize the models by applying the EqualizedOdds parity constraint, which tries to ensure that models that exhibit similar true and false positive rates for each sensitive feature grouping.\n",
    "    dashboard_title = \"Fairness insights of Diabetes Classifier\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "\n",
    "    # To test the dashboard, you can download it\n",
    "    downloaded_dict = download_dashboard_by_upload_id(run, upload_id)\n",
    "    print(downloaded_dict)\n",
    "    \n",
    "finally:\n",
    "    run.complete()\n",
    "    \n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigate Unfairness for the Model\n",
    "Now that you've analyzed the model for fairness, you can use any of the mitigation techniques supported by the FairLearn package to find a model that achieves the best balance of predictive performance and fairness.\n",
    "In this exercise, you'll use the GridSearch feature, which trains multiple models in an attempt to minimize the disparity of predictive performance for the sensitive features in the dataset (in this case, the age groups). You'll optimize the models by applying the EqualizedOdds parity constraint, which tries to ensure that models that exhibit similar true and false positive rates for each sensitive feature grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, EqualizedOdds\n",
    "import joblib\n",
    "import os\n",
    "print('Finding mitigated models...')\n",
    "\n",
    "# Train multiple models\n",
    "sweep = GridSearch(DecisionTreeClassifier(),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=20)\n",
    "\n",
    "sweep.fit(X_train, y_train, sensitive_features=S_train.Age)\n",
    "models = sweep._predictors\n",
    "\n",
    "# Save the models and get predictions from them (plus the original unmitigated one for comparison)\n",
    "model_dir = 'mitigated_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_name = 'diabetes_unmitigated'\n",
    "print(model_name)\n",
    "joblib.dump(value=diabetes_model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "predictions = {model_name: diabetes_model.predict(X_test)}\n",
    "i = 0\n",
    "for model in models:\n",
    "    i += 1\n",
    "    model_name = 'diabetes_mitigated_{0}'.format(i)\n",
    "    print(model_name)\n",
    "    joblib.dump(value=model, filename=os.path.join(model_dir, '{0}.pkl'.format(model_name)))\n",
    "    predictions[model_name] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use fairlearn dashboard to compare the mitigated models. The following code visuliaze age by recall and measure disparity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FairlearnDashboard(sensitive_features=S_test, \n",
    "                   sensitive_feature_names=['Age'],\n",
    "                   y_true=y_test,\n",
    "                   y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are shown on a scatter plot. You can compare the models by measuring the disparity in predictions (in other words, the selection rate) or the disparity in the selected performance metric (in this case, recall). In this scenario, we expect disparity in selection rates (because we know that age is a factor in diabetes, with more positive cases in the older age group). What we're interested in is the disparity in predictive performance, so select the option to measure Disparity in recall.\n",
    "The chart shows clusters of models with the overall recall metric on the X axis, and the disparity in recall on the Y axis. Therefore, the ideal model (with high recall and low disparity) would be at the bottom right corner of the plot. You can choose the right balance of predictive performance and fairness for your particular needs, and select an appropriate model to see its details.\n",
    "An important point to reinforce is that applying fairness to a model is a trade-off between overall predictive performance and disparity across sensitive feature groups - generally you must sacrifice some overall predictive performance to ensure that the model predicts fairly for all segments of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the Mitigation Dashboard Metrics to Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the models\n",
    "registered_model_predictions = dict()\n",
    "for model_name, prediction_data in predictions.items():\n",
    "    model_file = os.path.join(model_dir, model_name + \".pkl\")\n",
    "    registered_model = Model.register(model_path=model_file,\n",
    "                                      model_name=model_name,\n",
    "                                      workspace=ws)\n",
    "    registered_model_predictions[registered_model.id] = prediction_data\n",
    "\n",
    "#  Create a group metric set for binary classification based on the Age feature for all of the models\n",
    "sf = { 'Age': S_test.Age}\n",
    "dash_dict = _create_group_metric_set(y_true=y_test,\n",
    "                                     predictions=registered_model_predictions,\n",
    "                                     sensitive_features=sf,\n",
    "                                     prediction_type='binary_classification')\n",
    "\n",
    "exp = Experiment(ws, \"Diabetes_Fairness_Mitigation\")\n",
    "print(exp)\n",
    "\n",
    "run = exp.start_logging()\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Upload the dashboard to Azure Machine Learning\n",
    "try:\n",
    "    dashboard_title = \"Fairness Comparison of Diabetes Models\"\n",
    "    upload_id = upload_dashboard_dictionary(run,\n",
    "                                            dash_dict,\n",
    "                                            dashboard_name=dashboard_title)\n",
    "    print(\"\\nUploaded to id: {0}\\n\".format(upload_id))\n",
    "finally:\n",
    "    run.complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
